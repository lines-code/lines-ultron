{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# update or install the necessary libraries\n",
    "%pip install --upgrade openai\n",
    "%pip install --upgrade langchain\n",
    "%pip install --upgrade langchain_community\n",
    "%pip install --upgrade python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for LangChain\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_open_params(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "):\n",
    "    \"\"\" set openai parameters\"\"\"\n",
    "\n",
    "    openai_params = {}    \n",
    "\n",
    "    openai_params['model'] = model\n",
    "    openai_params['temperature'] = temperature\n",
    "    openai_params['max_tokens'] = max_tokens\n",
    "    openai_params['top_p'] = top_p\n",
    "    openai_params['frequency_penalty'] = frequency_penalty\n",
    "    openai_params['presence_penalty'] = presence_penalty\n",
    "    return openai_params\n",
    "\n",
    "def get_completion(params, messages):\n",
    "    \"\"\" GET completion from openai api\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model = params['model'],\n",
    "        messages = messages,\n",
    "        temperature = params['temperature'],\n",
    "        max_tokens = params['max_tokens'],\n",
    "        top_p = params['top_p'],\n",
    "        frequency_penalty = params['frequency_penalty'],\n",
    "        presence_penalty = params['presence_penalty'],\n",
    "    )\n",
    "    return response\n",
    "\n",
    "params = set_open_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompt \n",
    "\n",
    "추가적인 학습 없이 새로운 데이터에 대한 예측을 할 수 있게 하는 기법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "빨간색 자동차는 일반적으로 자동차의 색상과 유형을 기준으로 분류할 수 있습니다. 예를 들어:\n",
       "\n",
       "1. **색상**: 빨간색\n",
       "2. **형태/유형**: 세단, SUV, 해치백, 스포츠카 등\n",
       "3. **브랜드**: 현대, 기아, 토요타, 포드 등\n",
       "4. **연료 유형**: 가솔린, 디젤, 전기차 등\n",
       "\n",
       "더 구체적인 분류를 원하시면 추가적인 정보를 제공해 주세요!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"이미지를 분류하세요:빨간색 자동차\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"이미지를 분류하세요:빨간색 자동차\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Positive"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the text into neutral, negative, or positive.\n",
    "Generate only the class, nothing else.\n",
    "Text: I think the food was awesome.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain-of-Thought (COT) Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's identify the odd numbers in the group: 15, 5, 13, 7, and 1. \n",
       "\n",
       "Now, let's add them together:\n",
       "- 15 + 5 = 20\n",
       "- 20 + 13 = 33\n",
       "- 33 + 7 = 40\n",
       "- 40 + 1 = 41\n",
       "\n",
       "The sum of the odd numbers (15, 5, 13, 7, 1) is 41, which is odd.\n",
       "\n",
       "Therefore, the statement is False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "A:\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Prompt\n",
    "\n",
    "모델의 작은 수의 예시를 제공하는 Prompt 기법입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To determine if the sum of the odd numbers in the group (15, 32, 5, 13, 82, 7, 1) is even or odd, we first identify the odd numbers:\n",
       "\n",
       "- Odd numbers: 15, 5, 13, 7, 1\n",
       "\n",
       "Now we add them together:\n",
       "\n",
       "15 + 5 + 13 + 7 + 1 = 41\n",
       "\n",
       "Since 41 is an odd number, the statement \"The odd numbers in this group add up to an even number\" is False.\n",
       "\n",
       "A: The answer is False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
    "A: The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
    "A: The answer is True.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
    "A: The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "A:\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#MoviesLover #Movies #MyMovies #BestMovie #MovieOfTheYear"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Genereate a single line of hashtags for the given topic by in the same style as the following examples:\n",
    "\n",
    "Topic: Books\n",
    "#BooksLover #Books #MyBooks #BestBook #BookOfTheYear\n",
    "\n",
    "Topic: Games\n",
    "#GamesLover #Games #MyGames #BestGame #GameOfTheYear\n",
    "\n",
    "Topic: Movies\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot - Chain of Thought "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's break this down step by step:\n",
       "\n",
       "1. **Initial Cupcakes Baked:**\n",
       "   - You baked 15 cupcakes.\n",
       "   - **Total cupcakes now: 15**\n",
       "\n",
       "2. **Cupcakes Given to Friends:**\n",
       "   - You gave 5 cupcakes to your friends.\n",
       "   - **Total cupcakes remaining: 15 - 5 = 10**\n",
       "\n",
       "3. **Cupcakes Baked Again:**\n",
       "   - You baked 4 more cupcakes.\n",
       "   - **Total cupcakes now: 10 + 4 = 14**\n",
       "\n",
       "4. **Cupcake Eaten by You:**\n",
       "   - You ate 1 cupcake.\n",
       "   - **Total cupcakes remaining: 14 - 1 = 13**\n",
       "\n",
       "So, after all these steps, you have **13 cupcakes** left."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"I baked 15 cupcakes for a bake sale. I wanted to share some\n",
    "with my friends so I gave 5 to my friends. Needing a few more\n",
    "for taste testing, I baked 4 more cupcakes.\n",
    "Later, I couldn't resist and a I ate 1 cupcake by myself.\n",
    "How many cupcakes do I have right now? Explain your thinking step by step\n",
    "including the number of cupcakes per step.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree of Thoughts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### 토론 주제: 1kg의 깃털과 1kg의 돌 중 어느 것이 더 무거운가?\n",
       "\n",
       "#### 전문가 1: 김박사\n",
       "안녕하세요, 여러분. 오늘의 주제에 대해 이야기해 보겠습니다. 간단히 말하자면, 1kg의 깃털과 1kg의 돌은 무게가 동일합니다. 두 물체 모두 1kg이기 때문에, 무게를 비교할 필요가 없습니다. 그러나 우리가 이 질문을 던졌을 때, 아마도 우리는 각 물체의 부피나 밀도를 생각할 것입니다.\n",
       "\n",
       "#### 전문가 2: 이교수\n",
       "맞습니다, 김박사님. 하지만 제가 강조하고 싶은 것은, 사람들은 종종 무게와 부피를 혼동합니다. 1kg의 깃털은 많은 공간을 차지하고, 1kg의 돌은 상대적으로 작은 공간을 차지합니다. 그래서 일반적인 사람들은 깃털이 더 가볍다고 느낄 수 있지만, 실제로는 두 물체의 무게는 동일하다는 점을 잊지 말아야 합니다.\n",
       "\n",
       "#### 전문가 3: 박연구원\n",
       "저도 동의합니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Simulate a multi turn debate of three korean experts using korean.\n",
    "They need to answer the following question: Which is heavier? 1kg of feathers or 1kg of stones?\n",
    "They need to debate in rounds and provide explaination until they reach the same conclusion. \"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Chaining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To convert the cities into a valid Python list, we will first extract the names, convert them to uppercase, and remove any unnecessary characters. The names from the text are:\n",
       "\n",
       "1. 김박사\n",
       "2. 이교수\n",
       "3. 정선생\n",
       "\n",
       "Now, let's convert them to uppercase and create a Python list:\n",
       "\n",
       "```python\n",
       "cities = [\"김박사\", \"이교수\", \"정선생\"]\n",
       "cities = [city.upper() for city in cities]\n",
       "```\n",
       "\n",
       "After applying the transformations, the final list in uppercase will be:\n",
       "\n",
       "```python\n",
       "cities = [\"김박사\", \"이교수\", \"정선생\"]\n",
       "```\n",
       "\n",
       "Please note that since these are Korean names, they will remain in Hangul but will be represented in uppercase as per your instruction."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_1 = \"\"\"\n",
    "Extract all city names from the following text:\n",
    "\n",
    "The aroma of fresh bread wafted through the Paris market, tempting Amelia\n",
    "as she hurried to catch her flight to Tokyo. She dreamt of indulging in steaming\n",
    "ramen after a whirlwind tour of ancient temples. Back home in Chicago,\n",
    "she'd recount her adventures, photos filled with Eiffel Tower selfies\n",
    "and neon-lit Tokyo nights.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)\n",
    "\n",
    "prompt_2 = f\"\"\"Convert the following cities into a valid Python list.\n",
    "Make it uppercase and remove all unecessary characters:\\n{response.choices[0].message.content}\"\"\"\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt_2\n",
    "    }\n",
    "]\n",
    "\n",
    "response_2 = get_completion(params, messages)\n",
    "IPython.display.Markdown(response_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 고급 프롬프트 엔지니어링 방법 \n",
    "\n",
    "## 프롬프트 주요 요소 \n",
    "\n",
    "- 역할 설정\n",
    "- 지시사항(필수)\n",
    "- 맥락(필수)\n",
    "- 입력데이터(필수)\n",
    "- 출력형식 \n",
    "- 예시 \n",
    "- 제약조건\n",
    "- 추가정보요청 \n",
    "- 평가기준\n",
    "\n",
    "## 프롬프트 구성 요소 \n",
    "\n",
    "- System 프롬프트 \n",
    "  - 주로 \"맥락\"과 \"역할설정\" 요소가 사용됨 \n",
    "- User 프롬프트 \n",
    "  - 거의 모든 프롬프트 구성 요소가 여기서 사용될 수 있음 \n",
    "\n",
    "## 검토되어야할 고급 예제 \n",
    "\n",
    "- 명확하고 구체적으로 지시하기 \n",
    "- 모델에 역할 부여하기 \n",
    "- XML 태그 사용하기 \n",
    "- 예시 사용하기 (Few-Shot Prompting)\n",
    "- 복잡한 프롬프트 연결하기 (Prompt Chaining)\n",
    "- 긴 프롬프트를 효과적으로 다루는 방법 \n",
    "- 환각 현상에 대처하기 위한 기술 \n",
    "- 프롬프트 인젝션 및 적대적 프롬프팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 명확하고 직접적인 지시하기 \n",
    "\n",
    "- 모호한 표현 대신 구제적이고 명확한 지시 사용하기 \n",
    "  - Domain Specific 한 구체적인 특정 정보를 작성해야한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델에게 역할을 부여하기 \n",
    "\n",
    "- 성능 향상과 함께 상황에 맞게 어도와 태도를 조정 \n",
    "  - 특히 특정 분야의 복잡한 시나리오에서 성능과 이해도 향상 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예시 사용하기 \n",
    "- 원하는 출력 형식의 구체적인 예시를 프롬프트에 제공 \n",
    "  - 실 사용 사레와 유사하고, 다양한 시나리오 및 엣지 케이스를 포함 \n",
    "  - 정해진 최적의 예시 수는 없으나, 최소 3-5개의 예시를 제공 \n",
    "  - 형식을 준수해야하는 작업에 효과적 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단계별로 생각하게 하기 \n",
    "\n",
    "- 복잡한 문제를 단계별로 생각하도록 함 \n",
    "- 다면적이거나 까다로운 질문에 대해 체계적으로 접근하도록 함 \n",
    "- 명시적으로 사고과정을 분석하도록 지시하여 보다 체계적이고 철저한 문제 해결 \n",
    "- 단계별로 추론에 대한 출력 길이를 증가시키면 지연시간에 영향을 줄 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 복잡한 프롬프트 연결하기 \n",
    "\n",
    "- 복잡한 작업을 하위 작업으로 나누고 프롬프트를 연결 \n",
    "- 한 프롬프트의 출력을 다른 프롬프트의 입력으로 사용 \n",
    "- 모델 Output 확인 후 응답을 개선하도록 요청해서 성능 개선 가능 \n",
    "\n",
    "> https://github.com/aws-samples/aws-ai-ml-workshop-kr/tree/master/genai/aws-gen-ai-kr/20_applications/10_prompt_chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 긴 프롬프트를 효과적으로 다루기 위한 방법 \n",
    "\n",
    "- 전체문서를 제공하여 컨텍스트를 보다 포관적으로 이해할 수 있어 더 나은 결과를 얻을 수 잇음 \n",
    "- 문서가 길거나 추가 배경 콘텐츠가 많은 경우 문서와 추가 자료가 세부 지침이나 사용자 쿼리보다 상단에 배치하는 것이 좋음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환각 현상을 대처하기 위한 기술 \n",
    "\n",
    "- \"모르겠습니다\" 라고 말할 수 있도록 허용 \n",
    "  - 프롬프트를 다음 문장으로 먼저 시작하기 : 확실하지 않거나 자신 있게 답변할 수 있는 정보가 충분하지 않은 경우에는 \"모르겠습니다\" 또는 \"확실하지 않습니다\"라고 답변하세요. \n",
    "\n",
    "- 직접적인 인용문을 요청 \n",
    "  - 질문과 관련하여 단어 단위의 인용문을 추출해 달라고 요청 \n",
    "  - 인용문이 없는 경우에는 \"관련 인용문을 찾을 수 없습니다\" 라고 요청 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프롬프트 인젝션 및 적대적 프롬프팅\n",
    "\n",
    "- 유해성 판별 쿼리를 미리 실행해서 사용자 입력의 적절성을 미리 평가하고, 유해한 프롬프트가 감지되면 쿼리의 응답을 차단 \n",
    "- 가드레일 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프롬프트 엔지니어링 사이클 \n",
    "- 테스트 케이스 개발 \n",
    "\n",
    "- 테이스 케이스 검증\n",
    "- 프롬프트 개선\n",
    "- 완성된 프롬프트 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
